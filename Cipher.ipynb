{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a6cd10-abd3-4afa-acf5-6910591ef5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sviatoslav/anaconda3/envs/vllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f981337-e763-467e-b971-bc48aa504155",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher = \"\"\"Xoi Doijtooi Tooijto-Ntoit-oo Toooj bot iott boi Giüobooj boi Öotoiooboooi to Jobi 4014 toit 40.000 Nojoioojojoo oot bto Xäoboi noo Ditnottooboo to Xootiobjoob joiobioopt. Dti zoo Jobioioobo iojjoo oi ioob 100.000 Dojojoo ioto. 4044 taootoo ooob otoooj io ntojo Nojoibäoboi btozotooooo. Xoiüpoi btoooi bot Toooj poiotti Iooioobo Tooijtoiootoboi, Loboitottoooo tüi Tjottioootoi oob Uäioooooooo pot iotooo Kooboo toitojjtoit. Noboo to oäobitoo Jobi taooto oto Iotj btoioi Dojojoo oji otooi boi jiaßtoo ntitoojjoo Kiottnoito to Toiooo oo Tooijtoooitt oottiotoo.\n",
    "\"\"\"\n",
    "text = \"\"\"Das Berliner Energie-Start-up Enpal hat seit der Gründung des Unternehmens im Jahr 2017 fast 70.000 Solaranlagen auf die Dächer von Privatkunden in Deutschland geschraubt. Bis zum Jahresende sollen es rund 100.000 Anlagen sein. 2025 könnten noch einmal so viele Solardächer hinzukommen. Darüber hinaus hat Enpal bereits Tausende Energiespeicher, Ladestationen für Elektroautos und Wärmepumpen bei seinen Kunden installiert. Schon im nächsten Jahr könnte ein Teil dieser Anlagen als eines der größten virtuellen Kraftwerke in Europa am Energiemarkt auftreten.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7824f46-4b74-46a5-9cc1-3991bc0bc08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 'enmaupoc',\n",
       " 't': 'ietfk',\n",
       " 'j': 'lgj',\n",
       " 'd': 'bpa',\n",
       " 'i': 'rst',\n",
       " '-': '-',\n",
       " 'n': 'svw',\n",
       " '4': '275',\n",
       " '0': '0',\n",
       " '1': '1',\n",
       " 'b': 'hd',\n",
       " 'ü': 'ü',\n",
       " 'z': 'z',\n",
       " 'p': 'b',\n",
       " '.': '.',\n",
       " 'ä': 'ä',\n",
       " 'a': 'ö',\n",
       " 'ß': 'ß',\n",
       " 'x': 'd',\n",
       " 'u': 'w',\n",
       " ',': ',',\n",
       " 'g': 'g',\n",
       " 'l': 'l',\n",
       " 'k': 'k',\n",
       " 'ö': 'u'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_list = cipher.lower().split(' ')\n",
    "cipher_list = [word.strip('.').strip('\\n') for word in cipher_list ] \n",
    "\n",
    "text_list = text.lower().split(' ')\n",
    "text_list = [word.strip('.').strip('\\n') for word in text_list ] \n",
    "\n",
    "pairs = {(i, k) for i,k in zip(cipher_list, text_list)}\n",
    "rules = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    for c, s in zip(pair[0],pair[1]):\n",
    "        if c in rules:\n",
    "            if s not in rules[c]:\n",
    "                rules[c] += s\n",
    "        else:\n",
    "            rules[c] = s\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835908f9-00c1-4f6f-8153-d01a472588d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "e\n",
      "f\n",
      "h\n",
      "m\n",
      "q\n",
      "r\n",
      "s\n",
      "v\n",
      "w\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "abc = ''.join([chr(ord('a')+i) for i in range(ord('z') - ord('a')+1)])\n",
    "for i in range(ord('z') - ord('a')):\n",
    "    ch = chr(ord('a')+i)\n",
    "    if ch not in rules:\n",
    "        print(ch)\n",
    "        rules[ch] = abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c9bfd6-1a5d-4b1b-b800-3e02ae57c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 'enmaupoc',\n",
       " 't': 'ietfk',\n",
       " 'j': 'lgj',\n",
       " 'd': 'bpa',\n",
       " 'i': 'rst',\n",
       " '-': '-',\n",
       " 'n': 'svw',\n",
       " '4': '275',\n",
       " '0': '0',\n",
       " '1': '1',\n",
       " 'b': 'hd',\n",
       " 'ü': 'ü',\n",
       " 'z': 'z',\n",
       " 'p': 'b',\n",
       " '.': '.',\n",
       " 'ä': 'ä',\n",
       " 'a': 'ö',\n",
       " 'ß': 'ß',\n",
       " 'x': 'd',\n",
       " 'u': 'w',\n",
       " ',': ',',\n",
       " 'g': 'g',\n",
       " 'l': 'l',\n",
       " 'k': 'k',\n",
       " 'ö': 'u',\n",
       " 'c': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'e': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'f': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'h': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'm': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'q': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'r': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 's': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'v': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'w': 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'y': 'abcdefghijklmnopqrstuvwxyz'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e1d6c1-44b3-466f-8a95-b5bd9cd10ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bei',\n",
       " 'bee',\n",
       " 'bet',\n",
       " 'bef',\n",
       " 'bek',\n",
       " 'bni',\n",
       " 'bne',\n",
       " 'bnt',\n",
       " 'bnf',\n",
       " 'bnk',\n",
       " 'bmi',\n",
       " 'bme',\n",
       " 'bmt',\n",
       " 'bmf',\n",
       " 'bmk',\n",
       " 'bai',\n",
       " 'bae',\n",
       " 'bat',\n",
       " 'baf',\n",
       " 'bak',\n",
       " 'bui',\n",
       " 'bue',\n",
       " 'but',\n",
       " 'buf',\n",
       " 'buk',\n",
       " 'bpi',\n",
       " 'bpe',\n",
       " 'bpt',\n",
       " 'bpk',\n",
       " 'boi',\n",
       " 'boe',\n",
       " 'bot',\n",
       " 'bof',\n",
       " 'bok',\n",
       " 'bci',\n",
       " 'bce',\n",
       " 'bct',\n",
       " 'bcf',\n",
       " 'bck',\n",
       " 'pei',\n",
       " 'pee',\n",
       " 'pet',\n",
       " 'pef',\n",
       " 'pek',\n",
       " 'pni',\n",
       " 'pne',\n",
       " 'pnt',\n",
       " 'pnf',\n",
       " 'pnk',\n",
       " 'pmi',\n",
       " 'pme',\n",
       " 'pmt',\n",
       " 'pmf',\n",
       " 'pmk',\n",
       " 'pai',\n",
       " 'pae',\n",
       " 'pat',\n",
       " 'paf',\n",
       " 'pak',\n",
       " 'pui',\n",
       " 'pue',\n",
       " 'put',\n",
       " 'puf',\n",
       " 'puk',\n",
       " 'ppi',\n",
       " 'ppe',\n",
       " 'ppt',\n",
       " 'ppk',\n",
       " 'poi',\n",
       " 'poe',\n",
       " 'pot',\n",
       " 'pof',\n",
       " 'pok',\n",
       " 'pci',\n",
       " 'pce',\n",
       " 'pct',\n",
       " 'pcf',\n",
       " 'pck',\n",
       " 'aei',\n",
       " 'aee',\n",
       " 'aet',\n",
       " 'aef',\n",
       " 'aek',\n",
       " 'ani',\n",
       " 'ane',\n",
       " 'ant',\n",
       " 'anf',\n",
       " 'ank',\n",
       " 'ami',\n",
       " 'ame',\n",
       " 'amt',\n",
       " 'amf',\n",
       " 'amk',\n",
       " 'aai',\n",
       " 'aae',\n",
       " 'aat',\n",
       " 'aaf',\n",
       " 'aak',\n",
       " 'aui',\n",
       " 'aue',\n",
       " 'aut',\n",
       " 'auf',\n",
       " 'auk',\n",
       " 'api',\n",
       " 'ape',\n",
       " 'apt',\n",
       " 'apf',\n",
       " 'apk',\n",
       " 'aoi',\n",
       " 'aoe',\n",
       " 'aot',\n",
       " 'aof',\n",
       " 'aok',\n",
       " 'aci',\n",
       " 'ace',\n",
       " 'act',\n",
       " 'acf',\n",
       " 'ack']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_german_word(word):\n",
    "    \"\"\"\n",
    "    Validates if a word follows German letter combination rules.\n",
    "    Returns True if the word is valid, False if it contains impossible combinations.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    \n",
    "    # 1. \"dt\" at the beginning of a word\n",
    "    if word.startswith('dt'):\n",
    "        return False\n",
    "    \n",
    "    # 2. \"ck\" at the beginning of a word\n",
    "    if word.startswith('ck'):\n",
    "        return False\n",
    "    \n",
    "    # 3. \"tz\" at the end without a vowel before it\n",
    "    if word.endswith('tz') and len(word) > 2:\n",
    "        if word[-3] not in 'aeiouäöü':\n",
    "            return False\n",
    "    \n",
    "    # 4. \"pf\", \"sch\", \"st\", \"sp\" at the end without a vowel before them\n",
    "    end_groups = ['pf', 'st', 'sp']\n",
    "    if any(word.endswith(group) and len(word) > len(group) and word[-(len(group)+1)] not in 'aeiouäöü' for group in end_groups):\n",
    "        return False\n",
    "    if word.endswith('sch') and len(word) > 3 and word[-4] not in 'aeiouäöü':\n",
    "        return False\n",
    "    \n",
    "    # 5. \"ä\", \"ö\", \"ü\" followed immediately by another vowel\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i] in 'äöü' and word[i+1] in 'aeiouäöüy':\n",
    "            return False\n",
    "    \n",
    "    # 6. \"ng\" at the beginning of a word\n",
    "    if word.startswith('ng'):\n",
    "        return False\n",
    "    \n",
    "    # 7. \"q\" without a following \"u\"\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i] == 'q' and word[i+1] != 'u':\n",
    "            return False\n",
    "    if word.endswith('q'):\n",
    "        return False\n",
    "    \n",
    "    # 8 & 9. \"dh\" and \"th\" in native German words\n",
    "    # This is hard to check programmatically as it depends on word origin\n",
    "    \n",
    "    # 10. \"aa\", \"ee\", \"oo\" are rare in native German words\n",
    "    # Since these are rare but not impossible, we'll skip this check\n",
    "    \n",
    "    # 11. \"y\" is rare in native German words\n",
    "    # Since it's rare but not impossible, we'll skip this check\n",
    "    \n",
    "    # 12. Triple consonants without a hyphen\n",
    "    consonants = 'bcdfghjklmnpqrstvwxz'\n",
    "    for i in range(len(word) - 2):\n",
    "        if (word[i] in consonants and \n",
    "            word[i+1] in consonants and \n",
    "            word[i+2] in consonants and\n",
    "            word[i] == word[i+1] == word[i+2]):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def produce_variants(word, rules=rules):\n",
    "    result = []\n",
    "    vectors = [list(rules[c]) for c in word]\n",
    "    for prod in it.product(*vectors):\n",
    "        word = ''.join(prod)\n",
    "        if is_valid_german_word(word):\n",
    "            yield word\n",
    "\n",
    "\n",
    "([var for var in produce_variants('dot')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f072e02-c3f3-481c-81a7-294f889a7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dbmdz/german-gpt2\"\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb52bce-ac3c-4403-b98f-288cae7d7e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  Doch\n",
      ".  Doch was\n",
      ".  Doch was passiert\n",
      ".  Doch was passiert wenn\n",
      ".  Doch was passiert wenn die\n",
      ".  Doch was passiert wenn die Künstliche\n"
     ]
    }
   ],
   "source": [
    "def decipher(text, model=model, tokenizer=tokenizer, rules=rules):\n",
    "    result = '. '\n",
    "    text_list = text.split(' ')\n",
    "    text_list = [word.strip('.').strip('\\n').strip(',') for word in text_list]\n",
    "    \n",
    "    for word in text_list:\n",
    "        if not word:\n",
    "            continue\n",
    "        inputs = tokenizer(result, return_tensors='pt')\n",
    "        \n",
    "        # Get model outputs (logits)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # Convert logits to probabilities using softmax\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "        variants = produce_variants(word.lower(), rules=rules)\n",
    "        max_prob = 0.0\n",
    "        best_var = ' '\n",
    "        for variant in variants:\n",
    "            tmp = ' '\n",
    "            if word.istitle():\n",
    "                tmp += variant.capitalize()\n",
    "            else:\n",
    "                tmp += variant\n",
    "            #next_token_id = tokenizer.encode(tmp)[0]  # Token ID for the next token \"example\"\n",
    "            #probability = probabilities[0, -1, next_token_id].item()\n",
    "            next_token_ids = tokenizer.encode(tmp)\n",
    "            probability = 1.0\n",
    "            for token_id in next_token_ids:\n",
    "                # Assuming we are calculating the probability of the next tokens after the input text\n",
    "                probability *= probabilities[0, -1, token_id].item()\n",
    "\n",
    "            if probability > max_prob:\n",
    "                max_prob = probability\n",
    "                best_var = tmp\n",
    "        result += best_var\n",
    "        print(result)\n",
    "    return result[3:]\n",
    "\n",
    "decipher('Xoob noi ooiitoit, nooo bto Küoitjtobo Iotojjtjooz ott tbioo Uoiboiiojoo tüi boi ntitoojjo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080afa7-0088-4004-a6fa-4a6ef3882b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

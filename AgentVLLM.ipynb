{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101cff18-967d-4844-a4fc-1f2bcc370a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sviatoslav/anaconda3/envs/vllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, Model, Tool, ChatMessage\n",
    "from smolagents.models import remove_stop_sequences\n",
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "os.environ['HF_TOKEN'] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf0f339-8e5c-408a-b018-ce8274d8872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-24 15:38:37 __init__.py:207] Automatically detected platform cpu.\n",
      "INFO 02-24 15:38:44 config.py:560] This model supports multiple tasks: {'classify', 'score', 'reward', 'generate', 'embed'}. Defaulting to 'generate'.\n",
      "WARNING 02-24 15:38:44 arg_utils.py:1223] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.\n",
      "WARNING 02-24 15:38:44 config.py:696] Async output processing is not supported on the current platform type cpu.\n",
      "WARNING 02-24 15:38:44 cpu.py:63] CUDA graph is not supported on CPU, fallback to the eager mode.\n",
      "WARNING 02-24 15:38:44 cpu.py:78] Environment variable VLLM_CPU_KVCACHE_SPACE (GB) for CPU backend is not set, using 4 by default.\n",
      "WARNING 02-24 15:38:44 cpu.py:99] uni is not supported on CPU, fallback to mp distributed executor backend.\n",
      "INFO 02-24 15:38:44 importing.py:16] Triton not installed or not compatible; certain GPU-related functions will not be available.\n",
      "INFO 02-24 15:38:44 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.4.dev53+geb24dc4a.d20250223+cpu) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 02-24 15:38:46 cpu.py:40] Using Torch SDPA backend.\n",
      "INFO 02-24 15:38:46 parallel_state.py:948] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 02-24 15:38:47 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
      "INFO 02-24 15:38:47 weight_utils.py:304] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.00it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-24 15:38:48 executor_base.py:111] # cpu blocks: 8192, # CPU blocks: 0\n",
      "INFO 02-24 15:38:48 executor_base.py:116] Maximum concurrency for 131072 tokens per request: 1.00x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-24 15:38:48 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 0.54 seconds\n"
     ]
    }
   ],
   "source": [
    "class VLLMModel(Model):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id: str,\n",
    "        sampling_kwargs: dict = None,\n",
    "        init_kwargs: dict = None,\n",
    "        chat_kw_args: dict = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        default_model_id = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "        if model_id is None:\n",
    "            model_id = default_model_id\n",
    "            logger.warning(f\"`model_id`not provided, using this default model: '{model_id}'\")\n",
    "        self.model_id = model_id\n",
    "        from vllm import LLM, SamplingParams\n",
    "        if not init_kwargs:\n",
    "            init_kwargs = {}\n",
    "        if not sampling_kwargs:\n",
    "            sampling_kwargs = {}\n",
    "        default_max_tokens = 5000\n",
    "        max_new_tokens = sampling_kwargs.get(\"max_new_tokens\") or sampling_kwargs.get(\"max_tokens\")\n",
    "        if not max_new_tokens:\n",
    "            kwargs[\"max_new_tokens\"] = default_max_tokens\n",
    "            logger.warning(\n",
    "                f\"`max_new_tokens` not provided, using this default value for `max_new_tokens`: {default_max_tokens}\"\n",
    "            )\n",
    "        self.kwargs = kwargs\n",
    "        self.sampling_params = SamplingParams(**sampling_kwargs)\n",
    "        self.model = LLM(model=model_name, **init_kwargs)\n",
    "        self._is_vlm = False\n",
    "\n",
    "        \n",
    "    def __call__(\n",
    "        self,\n",
    "        messages: List[Dict[str, str]],\n",
    "        stop_sequences: Optional[List[str]] = None,\n",
    "        grammar: Optional[str] = None,\n",
    "        tools_to_call_from: Optional[List[Tool]] = None,\n",
    "        images: Optional[List[Image.Image]] = None,\n",
    "        **kwargs,\n",
    "    ) -> ChatMessage:\n",
    "        max_new_tokens = (\n",
    "            kwargs.get(\"max_new_tokens\")\n",
    "            or kwargs.get(\"max_tokens\")\n",
    "            or self.kwargs.get(\"max_new_tokens\")\n",
    "            or self.kwargs.get(\"max_tokens\")\n",
    "        )\n",
    "        completion_kwargs = {}\n",
    "        if max_new_tokens:\n",
    "            completion_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        import torch\n",
    "\n",
    "        out = self.model.chat(messages, \n",
    "                              sampling_params=self.sampling_params,\n",
    "                              use_tqdm=False)\n",
    "        output = out[-1].outputs[-1].text\n",
    "        if stop_sequences is not None:\n",
    "            output = remove_stop_sequences(output, stop_sequences)\n",
    "        raw = {'output': torch.tensor(out[-1].outputs[-1].token_ids), \n",
    "               \"completion_kwargs\": completion_kwargs}\n",
    "        if tools_to_call_from is None:\n",
    "            return ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=output,\n",
    "                raw=raw,\n",
    "            )\n",
    "        else:\n",
    "            if \"Action:\" in output:\n",
    "                output = output.split(\"Action:\", 1)[1].strip()\n",
    "            try:\n",
    "                start_index = output.index(\"{\")\n",
    "                end_index = output.rindex(\"}\")\n",
    "                output = output[start_index : end_index + 1]\n",
    "            except Exception as e:\n",
    "                raise Exception(\"No json blob found in output!\") from e\n",
    "\n",
    "            try:\n",
    "                parsed_output = json.loads(output)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Tool call '{output}' has an invalid JSON structure: {e}\")\n",
    "            tool_name = parsed_output.get(\"name\")\n",
    "            tool_arguments = parsed_output.get(\"arguments\")\n",
    "            return ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    ChatMessageToolCall(\n",
    "                        id=\"\".join(random.choices(\"0123456789\", k=5)),\n",
    "                        type=\"function\",\n",
    "                        function=ChatMessageToolCallDefinition(name=tool_name, arguments=tool_arguments),\n",
    "                    )\n",
    "                ],\n",
    "                raw=raw,\n",
    "            )\n",
    "\n",
    "\n",
    "model_name = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "#model_name = \"facebook/opt-125m\"\n",
    "model = VLLMModel(model_name, sampling_kwargs={'max_tokens': 6000, 'temperature':0.8, 'top_p':0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964a5946-3c68-424f-aadb-d6d093893397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-24 15:38:49 chat_utils.py:332] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n",
      "WARNING 02-24 15:38:52 cpu.py:143] Pin memory is not supported on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatMessage(role='assistant', content=\"The Importance of Higher Education: Unlocking the Potential of the Next Generation\\n\\nHigher education has long been regarded as the key to unlocking the potential of individuals, societies, and economies. It is a cornerstone of modern civilization, providing individuals with the skills, knowledge, and expertise necessary to succeed in an increasingly complex and interconnected world. The importance of higher education cannot be overstated, and it is essential for fostering a more informed, productive, and prosperous society.\\n\\nOne of the primary reasons higher education is so crucial is that it equips individuals with the knowledge and skills necessary to compete in the modern job market. In today's global economy, the standard of living and economic growth are directly tied to the level of education and training. Higher education institutions provide students with access to a vast array of courses, programs, and research opportunities that can help them develop the skills and expertise required to succeed in their chosen field. For instance, studies have shown that individuals with higher levels of education tend to earn higher salaries, enjoy better job prospects, and experience reduced poverty rates.\\n\\nFurthermore, higher education plays a critical role in fostering a culture of innovation and creativity. By providing access to cutting-edge research and academic resources, universities and higher education institutions can stimulate the development of new ideas, technologies, and products. This, in turn, can lead to economic growth, job creation, and improved living standards. For example, many countries that have invested heavily in higher education have experienced rapid economic growth and innovation, as seen in the case of Singapore, which has become a hub for cutting-edge research and technology.\\n\\nHigher education also plays a vital role in addressing social and economic inequalities. By providing access to higher education, governments and institutions can help bridge the gap between the haves and have-nots, ensuring that everyone has the opportunity to develop the skills and knowledge necessary to participate fully in society. This, in turn, can help to reduce poverty, inequality, and social exclusion.\\n\\nAnother critical aspect of higher education is its ability to foster critical thinking, problem-solving, and collaboration skills. By encouraging students to think critically, explore complex issues, and work in teams, universities and higher education institutions can help to develop the skills necessary to tackle the complex problems facing our world today. This, in turn, can lead to improved decision-making, policy development, and community engagement.\\n\\nIn addition, higher education has a profound impact on social mobility. By providing opportunities for individuals to pursue higher education, universities and institutions can help to break down social barriers and promote social mobility. This can lead to a more diverse, inclusive, and equitable society, where everyone has the opportunity to succeed.\\n\\nFinally, higher education is essential for fostering a culture of lifelong learning and personal growth. As people's lives change and circumstances evolve, they need to continually update their skills and knowledge to remain competitive in the job market. Higher education institutions can play a critical role in helping individuals to develop these skills, ensuring that they are equipped to adapt to the rapidly changing world.\\n\\nIn conclusion, higher education is essential for fostering a more informed, productive, and prosperous society. It provides individuals with the knowledge, skills, and expertise necessary to compete in the modern job market, stimulate innovation and creativity, address social and economic inequalities, promote social mobility, and foster a culture of lifelong learning and personal growth. As we look to the future, it is clear that higher education will remain a critical component of a thriving and sustainable society.\\n\\nReferences:\\n\\n* Organisation for Economic Co-operation and Development (OECD). (2019). Education at a Glance 2019: Key Indicators.\\n* United Nations Educational, Scientific and Cultural Organization (UNESCO). (2019). Education for All by 2030.\\n* World Bank. (2020). Education at a Glance 2020.\\n\\nNote: The essay is based on available data and information up to the cut-off date.\", tool_calls=None, raw={'output': tensor([   791,  94100,    315,  35321,  11930,     25,  58530,    287,    279,\n",
       "         55057,    315,    279,   9479,  24367,    271,  88545,   6873,    706,\n",
       "          1317,   1027,  27458,    439,    279,   1401,    311,  80478,    279,\n",
       "          4754,    315,   7931,     11,  34775,     11,    323,  37671,     13,\n",
       "          1102,    374,    264,  82575,    315,   6617,  36017,     11,   8405,\n",
       "          7931,    449,    279,   7512,     11,   6677,     11,    323,  19248,\n",
       "          5995,    311,  12265,    304,    459,  15098,   6485,    323,  83416,\n",
       "          1917,     13,    578,  12939,    315,   5190,   6873,   4250,    387,\n",
       "         83509,    660,     11,    323,    433,    374,   7718,    369,  86644,\n",
       "           264,    810,  16369,     11,  27331,     11,    323,  71407,   8396,\n",
       "           382,   4054,    315,    279,   6156,   8125,   5190,   6873,    374,\n",
       "           779,  16996,    374,    430,    433,   3312,   3153,   7931,    449,\n",
       "           279,   6677,    323,   7512,   5995,    311,  20874,    304,    279,\n",
       "          6617,   2683,   3157,     13,    763,   3432,    596,   3728,   8752,\n",
       "            11,    279,   5410,    315,   5496,    323,   7100,   6650,    527,\n",
       "          6089,  17791,    311,    279,   2237,    315,   6873,    323,   4967,\n",
       "            13,  35321,   6873,  14673,   3493,   4236,    449,   2680,    311,\n",
       "           264,  13057,   1358,    315,  14307,     11,   7620,     11,    323,\n",
       "          3495,  10708,    430,    649,   1520,   1124,   2274,    279,   7512,\n",
       "           323,  19248,   2631,    311,  12265,    304,    872,  12146,   2115,\n",
       "            13,   1789,   2937,     11,   7978,    617,   6982,    430,   7931,\n",
       "           449,   5190,   5990,    315,   6873,   8541,    311,   7380,   5190,\n",
       "         37532,     11,   4774,   2731,   2683,  27949,     11,    323,   3217,\n",
       "         11293,  19542,   7969,    382,  57417,     11,   5190,   6873,  11335,\n",
       "           264,   9200,   3560,    304,  86644,    264,   7829,    315,  19297,\n",
       "           323,  28697,     13,   3296,   8405,   2680,    311,  14713,  48448,\n",
       "          3495,    323,  14584,   5070,     11,  23978,    323,   5190,   6873,\n",
       "         14673,    649,  51077,    279,   4500,    315,    502,   6848,     11,\n",
       "         14645,     11,    323,   3956,     13,   1115,     11,    304,   2543,\n",
       "            11,    649,   3063,    311,   7100,   6650,     11,   2683,   9886,\n",
       "            11,    323,  13241,   5496,  10886,     13,   1789,   3187,     11,\n",
       "          1690,   5961,    430,    617,  29091,  17345,    304,   5190,   6873,\n",
       "           617,  10534,  11295,   7100,   6650,    323,  19297,     11,    439,\n",
       "          3970,    304,    279,   1162,    315,  21181,     11,    902,    706,\n",
       "          3719,    264,  19240,    369,  14713,  48448,   3495,    323,   5557,\n",
       "           382,  88545,   6873,   1101,  11335,    264,  16595,   3560,    304,\n",
       "         28118,   3674,    323,   7100,  93334,     13,   3296,   8405,   2680,\n",
       "           311,   5190,   6873,     11,  17047,    323,  14673,    649,   1520,\n",
       "         14497,    279,  13225,   1990,    279,    305,   4798,    323,    617,\n",
       "         30269,     82,     11,  23391,    430,   5127,    706,    279,   6776,\n",
       "           311,   2274,    279,   7512,    323,   6677,   5995,    311,  16136,\n",
       "          7373,    304,   8396,     13,   1115,     11,    304,   2543,     11,\n",
       "           649,   1520,    311,   8108,  19542,     11,  32305,     11,    323,\n",
       "          3674,  42308,    382,  14364,   9200,  13189,    315,   5190,   6873,\n",
       "           374,   1202,   5845,    311,  31087,   9200,   7422,     11,   3575,\n",
       "         99246,     11,    323,  20632,   7512,     13,   3296,  26921,   4236,\n",
       "           311,   1781,  41440,     11,  13488,   6485,   4819,     11,    323,\n",
       "           990,    304,   7411,     11,  23978,    323,   5190,   6873,  14673,\n",
       "           649,   1520,    311,   2274,    279,   7512,   5995,    311,  22118,\n",
       "           279,   6485,   5435,  13176,   1057,   1917,   3432,     13,   1115,\n",
       "            11,    304,   2543,     11,    649,   3063,    311,  13241,   5597,\n",
       "         28846,     11,   4947,   4500,     11,    323,   4029,  20392,    382,\n",
       "           644,   5369,     11,   5190,   6873,    706,    264,  28254,   5536,\n",
       "           389,   3674,  31139,     13,   3296,   8405,  10708,    369,   7931,\n",
       "           311,  23564,   5190,   6873,     11,  23978,    323,  14673,    649,\n",
       "          1520,    311,   1464,   1523,   3674,  30740,    323,  12192,   3674,\n",
       "         31139,     13,   1115,    649,   3063,    311,    264,    810,  17226,\n",
       "            11,  29408,     11,    323,  77109,   8396,     11,   1405,   5127,\n",
       "           706,    279,   6776,    311,  12265,    382,  24901,     11,   5190,\n",
       "          6873,    374,   7718,    369,  86644,    264,   7829,    315,  51263,\n",
       "          6975,    323,   4443,   6650,     13,   1666,   1274,    596,   6439,\n",
       "          2349,    323,  13463,  38680,     11,    814,   1205,    311,  35611,\n",
       "          2713,    872,   7512,    323,   6677,    311,   7293,  15022,    304,\n",
       "           279,   2683,   3157,     13,  35321,   6873,  14673,    649,   1514,\n",
       "           264,   9200,   3560,    304,  10695,   7931,    311,   2274,   1521,\n",
       "          7512,     11,  23391,    430,    814,    527,  19167,    311,  10737,\n",
       "           311,    279,  19019,  10223,   1917,    382,    644,  17102,     11,\n",
       "          5190,   6873,    374,   7718,    369,  86644,    264,    810,  16369,\n",
       "            11,  27331,     11,    323,  71407,   8396,     13,   1102,   5825,\n",
       "          7931,    449,    279,   6677,     11,   7512,     11,    323,  19248,\n",
       "          5995,    311,  20874,    304,    279,   6617,   2683,   3157,     11,\n",
       "         51077,  19297,    323,  28697,     11,   2686,   3674,    323,   7100,\n",
       "         93334,     11,  12192,   3674,  31139,     11,    323,  31087,    264,\n",
       "          7829,    315,  51263,   6975,    323,   4443,   6650,     13,   1666,\n",
       "           584,   1427,    311,    279,   3938,     11,    433,    374,   2867,\n",
       "           430,   5190,   6873,    690,   7293,    264,   9200,   3777,    315,\n",
       "           264,  53414,    323,  22556,   8396,    382,  32812,   1473,      9,\n",
       "         47843,    369,  23362,   3623,  67334,    323,  11050,    320,  53965,\n",
       "          6620,    570,    320,    679,     24,    570,  11930,    520,    264,\n",
       "          8444,    685,    220,    679,     24,     25,   5422,   2314,  43152,\n",
       "           627,      9,   3723,  19687,  46945,     11,  38130,    323,  41333,\n",
       "         21021,    320,   1899,  71466,    570,    320,    679,     24,    570,\n",
       "         11930,    369,   2052,    555,    220,   9639,     15,    627,      9,\n",
       "          4435,   8715,     13,    320,   2366,     15,    570,  11930,    520,\n",
       "           264,   8444,    685,    220,   2366,     15,    382,   9290,     25,\n",
       "           578,   9071,    374,   3196,    389,   2561,    828,    323,   2038,\n",
       "           709,    311,    279,   4018,  12744,   2457,     13, 128009]), 'completion_kwargs': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! How can I assist you today?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write an essay about the importance of higher education.\",\n",
    "    },\n",
    "]\n",
    "response = model(conversation)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7d74f-c5e8-4628-93f9-913af1c60bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">How many seconds would it take for a leopard at full speed to run through Pont des Arts?</span>                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ VLLMModel - meta-llama/Llama-3.2-1B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mHow many seconds would it take for a leopard at full speed to run through Pont des Arts?\u001b[0m                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m VLLMModel - meta-llama/Llama-3.2-1B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating model output:\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 147.69 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 147.69 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> math</span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Speed of the leopard in meters per second</span><span style=\"background-color: #272822\">                                                                    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">leopard_speed_mps </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">80</span><span style=\"background-color: #272822\">                                                                                         </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Distance covered by the leopard</span><span style=\"background-color: #272822\">                                                                              </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">distance </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">360</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># meters</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Calculate the time it would take for the leopard to run through the bridge</span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">time_to_run </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> distance </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">/</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> leopard_speed_mps</span><span style=\"background-color: #272822\">                                                                     </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Convert the time to seconds</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">time_in_seconds </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> time_to_run </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">3600</span><span style=\"background-color: #272822\">                                                                           </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"The time it would take for the leopard to run through Pont des Arts is\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, time_in_seconds, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"seconds\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">    </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">```</span><span style=\"background-color: #272822\">                                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Final answer:</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmath\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Speed of the leopard in meters per second\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mleopard_speed_mps\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m80\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Distance covered by the leopard\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mdistance\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m360\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# meters\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Calculate the time it would take for the leopard to run through the bridge\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mtime_to_run\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdistance\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m/\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mleopard_speed_mps\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Convert the time to seconds\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mtime_in_seconds\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtime_to_run\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m3600\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mThe time it would take for the leopard to run through Pont des Arts is\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtime_in_seconds\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mseconds\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m    \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;237;0;126;48;2;30;0;16m`\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m`\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m`\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mFinal\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code parsing failed on line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">16</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> due to: SyntaxError</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">```</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> ^</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error: invalid syntax (&lt;unknown&gt;, line </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">16</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode parsing failed on line \u001b[0m\u001b[1;31m16\u001b[0m\u001b[1;31m due to: SyntaxError\u001b[0m\n",
       "\u001b[1;31m```\u001b[0m\n",
       "\u001b[1;31m ^\u001b[0m\n",
       "\u001b[1;31mError: invalid syntax \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m<\u001b[0m\u001b[1;31munknown\u001b[0m\u001b[1;31m>\u001b[0m\u001b[1;31m, line \u001b[0m\u001b[1;31m16\u001b[0m\u001b[1;31m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 225.69 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 225.69 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)\n",
    "\n",
    "agent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5551f71-4d34-43a8-9017-d0d44f686c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
